{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('wvs.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V2</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>...</th>\n",
       "      <th>MN_228S8</th>\n",
       "      <th>MN_229A</th>\n",
       "      <th>MN_230A</th>\n",
       "      <th>MN_233A</th>\n",
       "      <th>MN_237B1</th>\n",
       "      <th>MN_249A1</th>\n",
       "      <th>MN_249A3</th>\n",
       "      <th>I_RELIGBEL</th>\n",
       "      <th>I_NORM1</th>\n",
       "      <th>I_VOICE1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 328 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   V2  V4  V5  V6  V7  V8  V9  V10  V11  V12  ...  MN_228S8  MN_229A  MN_230A  \\\n",
       "0  12   1   1   1  -2   1   1    2    1    1  ...         3       -3       -3   \n",
       "1  12   1   2   3   4   2   2    2    2    2  ...         3       -3       -3   \n",
       "2  12   1   3   2   4   2   1    2    2    2  ...         4        1        1   \n",
       "3  12   1   1   3   4   3   1    2    1    2  ...         2        2        1   \n",
       "4  12   1   1   1   2   1   1    1    3    2  ...         2        2        1   \n",
       "\n",
       "   MN_233A  MN_237B1  MN_249A1  MN_249A3  I_RELIGBEL  I_NORM1  I_VOICE1  \n",
       "0       -3        -3         1         1         0.0      1.0      0.00  \n",
       "1       -3        -3         2        -1         0.0      1.0      0.66  \n",
       "2        2        -3         1         1         0.0      1.0      0.33  \n",
       "3        2        -3         1         2         0.0      1.0      0.00  \n",
       "4        2        -3         1         2         0.0      1.0      0.66  \n",
       "\n",
       "[5 rows x 328 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Explore and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking all V23 values with value less than 0\n",
    "drop_index = df[df['V23']<0]['V23'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping index where V23 values with value less than 0\n",
    "df.drop(index=drop_index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting index\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Null Values\n",
    "df['V23'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8     18213\n",
      "7     15493\n",
      "10    11928\n",
      "5     11331\n",
      "6     10666\n",
      "9      9264\n",
      "4      4600\n",
      "3      3463\n",
      "1      2828\n",
      "2      1985\n",
      "Name: V23, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Value counts of each satisfaction level. \n",
    "print(df['V23'].value_counts())\n",
    "v23_6 = df[df['V23']>=6]['V23'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean satisfaction level:  6.8290316471911865\n",
      "Proportion of V23 values greater than 6: 0.7303472168072095\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean satisfaction level: \",df['V23'].mean())\n",
    "print(\"Proportion of V23 values greater than 6:\",v23_6.sum()/len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Create the Design Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Firstly let's decide the variables to input, and remove the missing variables. The last stage would be creating the Y matrix. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89771"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['V2', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12',\n",
      "       ...\n",
      "       'MN_228S8', 'MN_229A', 'MN_230A', 'MN_233A', 'MN_237B1', 'MN_249A1',\n",
      "       'MN_249A3', 'I_RELIGBEL', 'I_NORM1', 'I_VOICE1'],\n",
      "      dtype='object', length=328)\n",
      "\n",
      "\n",
      "          index      0\n",
      "0            V2      0\n",
      "325  I_RELIGBEL      0\n",
      "299       V258A      0\n",
      "326     I_NORM1      0\n",
      "20          V23      0\n",
      "..          ...    ...\n",
      "135     V125_11  88697\n",
      "137     V125_13  88712\n",
      "250     V215_15  88720\n",
      "127     V125_02  88986\n",
      "55       V56_NZ  88999\n",
      "\n",
      "[328 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Checking columns with the least missing values\n",
    "missing_df = pd.DataFrame(df_mod.lt(0).sum())\n",
    "print(missing_df.index)\n",
    "missing_df.reset_index(inplace=True)\n",
    "missing_df.reset_index(drop=True, inplace=True)\n",
    "missing_df = missing_df.sort_values(by=0)\n",
    "print('\\n')\n",
    "print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_mod[['V23','V80','V2','V4','V22','V13','V14','V16','V18','V17','V12','V44','V20','V15','V19','V21','V240','V242','V57','V11','V5','V59','V10','V25', 'V6','V248','V84','V26','V27','V32','V30','V34','V200','V9','V55','V33','V188', 'V82', 'V102', 'V208', 'V209', 'V210', 'V179', 'V211', 'V8']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_new[(df_new[['V23', 'V80', 'V2', 'V4', 'V22', 'V13', 'V14', 'V16', 'V18', 'V17','V12', 'V44', 'V20', 'V15', 'V19', 'V21', 'V240', 'V242', 'V57', 'V11','V5', 'V59', 'V10', 'V25', 'V6', 'V248', 'V84', 'V26', 'V27', 'V32','V30', 'V34', 'V200', 'V9', 'V55', 'V33', 'V188', 'V82', 'V102', 'V208','V209', 'V210', 'V179', 'V211', 'V8']] != 0).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_v80 = (df_final[['V80']])\n",
    "var_v80.rename(columns={'V80':'Problems'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([-1, 1, 2, 3, 4, 5], dtype='int64')"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_v80.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "var_v80.drop(columns=var_v80.columns[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saransharora/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4223: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "var_v2.rename(columns={'V2':'Country'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_v2 = df_final['V2']\n",
    "var_v2 = pd.get_dummies(df_final['V2'])\n",
    "# Dropping one column\n",
    "var_v2.drop(columns=var_v2.columns[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saransharora/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "# Dropping columns V80 and V2 from df_final\n",
    "df_final.drop(columns=['V80','V2'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([df_final,var_v80, var_v2], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data['V23']\n",
    "data_X = data.drop(columns=['V23'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final two dataframes are now Y and data_X\n"
     ]
    }
   ],
   "source": [
    "print(\"The final two dataframes are now Y and data_X\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Condition numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4231, 1)\n",
      "Adding Variable : V4 , 0 columns, k =  1.0\n",
      "(4231, 2)\n",
      "Adding Variable : V22 , 1 columns, k =  4.433756879201765\n",
      "(4231, 3)\n",
      "Adding Variable : V13 , 2 columns, k =  5.350764399127095\n",
      "(4231, 4)\n",
      "Adding Variable : V14 , 3 columns, k =  6.1865243142415665\n",
      "(4231, 5)\n",
      "Adding Variable : V16 , 4 columns, k =  7.120869480720606\n",
      "(4231, 6)\n",
      "Adding Variable : V18 , 5 columns, k =  8.107501437947478\n",
      "(4231, 7)\n",
      "Adding Variable : V17 , 6 columns, k =  8.989703876341956\n",
      "(4231, 8)\n",
      "Adding Variable : V12 , 7 columns, k =  9.657491664192227\n",
      "(4231, 9)\n",
      "Adding Variable : V44 , 8 columns, k =  10.750662744852532\n",
      "(4231, 10)\n",
      "Adding Variable : V20 , 9 columns, k =  11.51204508562216\n",
      "(4231, 11)\n",
      "Adding Variable : V15 , 10 columns, k =  12.550246574983666\n",
      "(4231, 12)\n",
      "Adding Variable : V19 , 11 columns, k =  13.145671814159368\n",
      "(4231, 13)\n",
      "Adding Variable : V21 , 12 columns, k =  13.743742489604339\n",
      "(4231, 14)\n",
      "Adding Variable : V240 , 13 columns, k =  14.221665736886619\n",
      "(4231, 15)\n",
      "Adding Variable : V242 , 14 columns, k =  105.09513799662494\n",
      "(4231, 16)\n",
      "Adding Variable : V57 , 15 columns, k =  105.26086441872089\n",
      "(4231, 17)\n",
      "Adding Variable : V11 , 16 columns, k =  105.35775034612139\n",
      "(4231, 18)\n",
      "Adding Variable : V5 , 17 columns, k =  105.66906785594874\n",
      "(4231, 19)\n",
      "Adding Variable : V59 , 18 columns, k =  106.66375391767089\n",
      "(4231, 20)\n",
      "Adding Variable : V10 , 19 columns, k =  106.89544229378544\n",
      "(4231, 21)\n",
      "Adding Variable : V25 , 20 columns, k =  106.94113727127393\n",
      "(4231, 22)\n",
      "Adding Variable : V6 , 21 columns, k =  107.0238689114013\n",
      "(4231, 23)\n",
      "Adding Variable : V248 , 22 columns, k =  107.78747632170489\n",
      "(4231, 24)\n",
      "Adding Variable : V84 , 23 columns, k =  107.92403933563277\n",
      "(4231, 25)\n",
      "Adding Variable : V26 , 24 columns, k =  107.95250962247131\n",
      "(4231, 26)\n",
      "Adding Variable : V27 , 25 columns, k =  107.97873414041628\n",
      "(4231, 27)\n",
      "Adding Variable : V32 , 26 columns, k =  108.0526135325857\n",
      "(4231, 28)\n",
      "Adding Variable : V30 , 27 columns, k =  108.07240607554107\n",
      "(4231, 29)\n",
      "Adding Variable : V34 , 28 columns, k =  108.1129228995856\n",
      "(4231, 30)\n",
      "Adding Variable : V200 , 29 columns, k =  108.35008272180785\n",
      "(4231, 31)\n",
      "Adding Variable : V9 , 30 columns, k =  108.43876102193109\n",
      "(4231, 32)\n",
      "Adding Variable : V55 , 31 columns, k =  109.68818076901212\n",
      "(4231, 33)\n",
      "Adding Variable : V33 , 32 columns, k =  109.72806890815713\n",
      "(4231, 34)\n",
      "Adding Variable : V188 , 33 columns, k =  109.99968330666069\n",
      "(4231, 35)\n",
      "Adding Variable : V82 , 34 columns, k =  110.2923897253869\n",
      "(4231, 36)\n",
      "Adding Variable : V102 , 35 columns, k =  110.35812413210938\n",
      "(4231, 37)\n",
      "Adding Variable : V208 , 36 columns, k =  110.61562181164092\n",
      "(4231, 38)\n",
      "Adding Variable : V209 , 37 columns, k =  111.01941234298332\n",
      "(4231, 39)\n",
      "Adding Variable : V210 , 38 columns, k =  111.21131487339866\n",
      "(4231, 40)\n",
      "Adding Variable : V179 , 39 columns, k =  111.68407825680704\n",
      "(4231, 41)\n",
      "Adding Variable : V211 , 40 columns, k =  111.74061953907776\n",
      "(4231, 42)\n",
      "Adding Variable : V8 , 41 columns, k =  111.96714228019133\n",
      "(4231, 43)\n",
      "Adding Variable : 1 , 42 columns, k =  112.61898579012703\n",
      "(4231, 44)\n",
      "Adding Variable : 2 , 43 columns, k =  153.59774395520304\n",
      "(4231, 45)\n",
      "Adding Variable : 3 , 44 columns, k =  198.2691059008846\n",
      "(4231, 46)\n",
      "Adding Variable : 4 , 45 columns, k =  284.0320013116914\n",
      "(4231, 47)\n",
      "Adding Variable : 5 , 46 columns, k =  759.1631964135892\n",
      "(4231, 48)\n",
      "Adding Variable : 32 , 47 columns, k =  760.6895724319423\n",
      "(4231, 49)\n",
      "Adding Variable : 36 , 48 columns, k =  760.9190391138105\n",
      "(4231, 50)\n",
      "Adding Variable : 48 , 49 columns, k =  765.2556668976687\n",
      "(4231, 51)\n",
      "Adding Variable : 51 , 50 columns, k =  1687.06215328215\n",
      "(4231, 52)\n",
      "Adding Variable : 76 , 51 columns, k =  1687.0622318363764\n",
      "(4231, 53)\n",
      "Adding Variable : 112 , 52 columns, k =  2061.534374132909\n",
      "(4231, 54)\n",
      "Adding Variable : 152 , 53 columns, k =  2061.544429634761\n",
      "(4231, 55)\n",
      "Adding Variable : 156 , 54 columns, k =  2061.5551712180436\n",
      "(4231, 56)\n",
      "Adding Variable : 158 , 55 columns, k =  2061.860454926261\n",
      "(4231, 57)\n",
      "Adding Variable : 170 , 56 columns, k =  2061.862390148715\n",
      "(4231, 58)\n",
      "Adding Variable : 196 , 57 columns, k =  2061.865330312167\n",
      "(4231, 59)\n",
      "Adding Variable : 218 , 58 columns, k =  2061.8662609682774\n",
      "(4231, 60)\n",
      "Adding Variable : 233 , 59 columns, k =  2061.8692473700225\n",
      "(4231, 61)\n",
      "Adding Variable : 268 , 60 columns, k =  2922.9067634560574\n",
      "(4231, 62)\n",
      "Adding Variable : 275 , 61 columns, k =  2922.933795264545\n",
      "(4231, 63)\n",
      "Adding Variable : 276 , 62 columns, k =  2922.9370138804766\n",
      "(4231, 64)\n",
      "Adding Variable : 288 , 63 columns, k =  2923.0018132819873\n",
      "(4231, 65)\n",
      "Adding Variable : 344 , 64 columns, k =  2923.027727444552\n",
      "(4231, 66)\n",
      "Adding Variable : 356 , 65 columns, k =  2923.129140790712\n",
      "(4231, 67)\n",
      "Adding Variable : 368 , 66 columns, k =  2923.1360717343405\n",
      "(4231, 68)\n",
      "Adding Variable : 392 , 67 columns, k =  2923.137899552669\n",
      "(4231, 69)\n",
      "Adding Variable : 398 , 68 columns, k =  2923.140803226558\n",
      "(4231, 70)\n",
      "Adding Variable : 400 , 69 columns, k =  2923.1413068570514\n",
      "(4231, 71)\n",
      "Adding Variable : 410 , 70 columns, k =  2925.278543069326\n",
      "(4231, 72)\n",
      "Adding Variable : 414 , 71 columns, k =  2926.2648272630286\n",
      "(4231, 73)\n",
      "Adding Variable : 417 , 72 columns, k =  2926.2781392188435\n",
      "(4231, 74)\n",
      "Adding Variable : 422 , 73 columns, k =  2926.3242694087353\n",
      "(4231, 75)\n",
      "Adding Variable : 434 , 74 columns, k =  2926.480166506021\n",
      "(4231, 76)\n",
      "Adding Variable : 458 , 75 columns, k =  2926.483519513335\n",
      "(4231, 77)\n",
      "Adding Variable : 484 , 76 columns, k =  2926.5240915736276\n",
      "(4231, 78)\n",
      "Adding Variable : 504 , 77 columns, k =  2926.6908798617037\n",
      "(4231, 79)\n",
      "Adding Variable : 528 , 78 columns, k =  2926.692549451327\n",
      "(4231, 80)\n",
      "Adding Variable : 554 , 79 columns, k =  2926.9744952580895\n",
      "(4231, 81)\n",
      "Adding Variable : 566 , 80 columns, k =  2927.0479130287563\n",
      "(4231, 82)\n",
      "Adding Variable : 586 , 81 columns, k =  2935.576691436092\n",
      "(4231, 83)\n",
      "Adding Variable : 604 , 82 columns, k =  2935.5949905200478\n",
      "(4231, 84)\n",
      "Adding Variable : 608 , 83 columns, k =  2935.7128419128985\n",
      "(4231, 85)\n",
      "Adding Variable : 616 , 84 columns, k =  2935.720634741688\n",
      "(4231, 86)\n",
      "Adding Variable : 634 , 85 columns, k =  2935.785220044813\n",
      "(4231, 87)\n",
      "Adding Variable : 642 , 86 columns, k =  2935.8474868892777\n",
      "(4231, 88)\n",
      "Adding Variable : 643 , 87 columns, k =  2935.995799973809\n",
      "(4231, 89)\n",
      "Adding Variable : 646 , 88 columns, k =  2936.1431791736222\n",
      "(4231, 90)\n",
      "Adding Variable : 702 , 89 columns, k =  2936.169800378286\n",
      "(4231, 91)\n",
      "Adding Variable : 705 , 90 columns, k =  2936.170261924077\n",
      "(4231, 92)\n",
      "Adding Variable : 710 , 91 columns, k =  2936.4245949358456\n",
      "(4231, 93)\n",
      "Adding Variable : 716 , 92 columns, k =  2936.4813060193187\n",
      "(4231, 94)\n",
      "Adding Variable : 724 , 93 columns, k =  2936.4845087639487\n",
      "(4231, 95)\n",
      "Adding Variable : 752 , 94 columns, k =  2936.525761913376\n",
      "(4231, 96)\n",
      "Adding Variable : 764 , 95 columns, k =  2938.7962071231814\n",
      "(4231, 97)\n",
      "Adding Variable : 780 , 96 columns, k =  2951.398920475376\n",
      "(4231, 98)\n",
      "Adding Variable : 788 , 97 columns, k =  2952.3866165323525\n",
      "(4231, 99)\n",
      "Adding Variable : 792 , 98 columns, k =  2953.6480451376715\n",
      "(4231, 100)\n",
      "Adding Variable : 804 , 99 columns, k =  2955.7129763205926\n",
      "(4231, 101)\n",
      "Adding Variable : 840 , 100 columns, k =  3243.078612884377\n",
      "(4231, 102)\n",
      "Adding Variable : 858 , 101 columns, k =  3510.6041985534234\n",
      "(4231, 103)\n",
      "Adding Variable : 860 , 102 columns, k =  3744.7744939249983\n",
      "(4231, 104)\n",
      "Adding Variable : 887 , 103 columns, k =  4570.048578305534\n"
     ]
    }
   ],
   "source": [
    "list_columns = []\n",
    "cond = []\n",
    "i_val = []\n",
    "for i in range(len(data_X.columns)):\n",
    "    list_columns.append(data_X.columns[i])\n",
    "    dat = data_X[list_columns]\n",
    "    a = dat.values\n",
    "    a = a.reshape(-1,len(dat.columns))\n",
    "    print(a.shape)\n",
    "    print(\"Adding Variable :\",data_X.columns[i],\",\", i, \"columns,\", \"k = \",np.linalg.cond(a))\n",
    "    i_val.append(i)\n",
    "    cond.append(np.linalg.cond(a))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x15ad75e90>"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(i_val, cond)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Do Some Social Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "life_satis = Y\n",
    "health = data_X['V11']\n",
    "control_life = data_X['V55']\n",
    "financial_sit = data_X['V59']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a linear regression models explaining satisfaction with these three variables. Present the output table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0        1\n",
      "V11  2.890649  3.00755\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                    V23   R-squared (uncentered):                   0.698\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.698\n",
      "Method:                 Least Squares   F-statistic:                              9785.\n",
      "Date:                Fri, 06 Mar 2020   Prob (F-statistic):                        0.00\n",
      "Time:                        22:37:54   Log-Likelihood:                         -11879.\n",
      "No. Observations:                4231   AIC:                                  2.376e+04\n",
      "Df Residuals:                    4230   BIC:                                  2.377e+04\n",
      "Df Model:                           1                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "V11            2.9491      0.030     98.917      0.000       2.891       3.008\n",
      "==============================================================================\n",
      "Omnibus:                      186.596   Durbin-Watson:                   1.369\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              216.504\n",
      "Skew:                          -0.505   Prob(JB):                     9.70e-48\n",
      "Kurtosis:                       3.458   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Life Satisfaction vs Health\n",
    "model = sm.OLS(life_satis, health)\n",
    "results = model.fit()\n",
    "print(results.conf_int())\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0        1\n",
      "V55  0.903195  0.92458\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                    V23   R-squared (uncentered):                   0.869\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.869\n",
      "Method:                 Least Squares   F-statistic:                          2.808e+04\n",
      "Date:                Fri, 06 Mar 2020   Prob (F-statistic):                        0.00\n",
      "Time:                        22:37:57   Log-Likelihood:                         -10112.\n",
      "No. Observations:                4231   AIC:                                  2.023e+04\n",
      "Df Residuals:                    4230   BIC:                                  2.023e+04\n",
      "Df Model:                           1                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "V55            0.9139      0.005    167.568      0.000       0.903       0.925\n",
      "==============================================================================\n",
      "Omnibus:                      411.953   Durbin-Watson:                   1.656\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2137.667\n",
      "Skew:                           0.321   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.423   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# # Life Satisfaction vs Control over Life\n",
    "model = sm.OLS(life_satis, control_life)\n",
    "results = model.fit()\n",
    "print(results.conf_int())\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1\n",
      "V59  0.993548  1.016787\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                    V23   R-squared (uncentered):                   0.872\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.872\n",
      "Method:                 Least Squares   F-statistic:                          2.876e+04\n",
      "Date:                Fri, 06 Mar 2020   Prob (F-statistic):                        0.00\n",
      "Time:                        22:37:59   Log-Likelihood:                         -10068.\n",
      "No. Observations:                4231   AIC:                                  2.014e+04\n",
      "Df Residuals:                    4230   BIC:                                  2.014e+04\n",
      "Df Model:                           1                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "V59            1.0052      0.006    169.594      0.000       0.994       1.017\n",
      "==============================================================================\n",
      "Omnibus:                      422.275   Durbin-Watson:                   1.694\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1587.149\n",
      "Skew:                           0.454   Prob(JB):                         0.00\n",
      "Kurtosis:                       5.860   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Life Satisfaction vs Financial Situation\n",
    "model = sm.OLS(life_satis, financial_sit)\n",
    "results = model.fit()\n",
    "print(results.conf_int())\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining Target and response variable in one dataframe\n",
    "data_comb = pd.concat([data_X,Y], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Adjusted R-squared is high for Control over Life and Financial Sitution, however, it is not that high for Health. This is surprising for me!\n"
     ]
    }
   ],
   "source": [
    "# Comment the output table in terms of relative effect size and statistical significance. Any surprises for you?\n",
    "\n",
    "print(\"\"\"The Adjusted R-squared is high for Control over Life and Financial Sitution, however, it is not that high for Health. This is surprising for me!\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and present RMSE (just on training data). This will serve as the benchmark for the future.\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_X, Y, test_size=0.2)\n",
    "model = sm.OLS(y_train, X_train).fit()\n",
    "predictions = model.predict(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.808979329478717\n"
     ]
    }
   ],
   "source": [
    "print(rmse(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Back to ML: Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition number for the design matrix : 4570.048578305534\n"
     ]
    }
   ],
   "source": [
    "print(\"Condition number for the design matrix :\",np.linalg.cond(data_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training-validation chunks\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition number for the training matrix : 4363.237904980998\n"
     ]
    }
   ],
   "source": [
    "#Condition number for training matrix\n",
    "print(\"Condition number for the training matrix :\",np.linalg.cond(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "model = lm.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for training dataset : 6.931676141926805e-16\n",
      "RMSE for testing dataset : 0.053109902402489056\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE for training dataset :\",(np.sqrt(np.mean(y_train-y_train_pred)**2)))\n",
    "print(\"RMSE for testing dataset :\",(np.sqrt(np.mean(y_test-y_pred)**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing around with Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for training dataset : 7.083905303695739e-16\n",
      "RMSE for testing dataset : 0.05592713793922389\n"
     ]
    }
   ],
   "source": [
    "r = Ridge(alpha=0.1)\n",
    "model = r.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"RMSE for training dataset :\",(np.sqrt(np.mean(y_train-y_train_pred)**2)))\n",
    "print(\"RMSE for testing dataset :\",(np.sqrt(np.mean(y_test-y_pred)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for training dataset : 5.398885961356848e-16\n",
      "RMSE for testing dataset : 0.06183164068660839\n"
     ]
    }
   ],
   "source": [
    "r = Ridge(alpha=1)\n",
    "model = r.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"RMSE for training dataset :\",(np.sqrt(np.mean(y_train-y_train_pred)**2)))\n",
    "print(\"RMSE for testing dataset :\",(np.sqrt(np.mean(y_test-y_pred)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for training dataset : 2.816239492725279e-16\n",
      "RMSE for testing dataset : 0.06380290575213357\n"
     ]
    }
   ],
   "source": [
    "r = Ridge(alpha=2)\n",
    "model = r.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"RMSE for training dataset :\",(np.sqrt(np.mean(y_train-y_train_pred)**2)))\n",
    "print(\"RMSE for testing dataset :\",(np.sqrt(np.mean(y_test-y_pred)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for training dataset : 2.5668986243106456e-16\n",
      "RMSE for testing dataset : 0.06496620112821755\n"
     ]
    }
   ],
   "source": [
    "r = Ridge(alpha=3)\n",
    "model = r.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"RMSE for training dataset :\",(np.sqrt(np.mean(y_train-y_train_pred)**2)))\n",
    "print(\"RMSE for testing dataset :\",(np.sqrt(np.mean(y_test-y_pred)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for training dataset : 5.729590692096257e-16\n",
      "RMSE for testing dataset : 0.06632061005160704\n"
     ]
    }
   ],
   "source": [
    "r = Ridge(alpha=5)\n",
    "model = r.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"RMSE for training dataset :\",(np.sqrt(np.mean(y_train-y_train_pred)**2)))\n",
    "print(\"RMSE for testing dataset :\",(np.sqrt(np.mean(y_test-y_pred)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for training dataset : 7.160019884580206e-16\n",
      "RMSE for testing dataset : 0.05349439644468733\n"
     ]
    }
   ],
   "source": [
    "r = Ridge(alpha=0.01)\n",
    "model = r.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"RMSE for training dataset :\",(np.sqrt(np.mean(y_train-y_train_pred)**2)))\n",
    "print(\"RMSE for testing dataset :\",(np.sqrt(np.mean(y_test-y_pred)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for training dataset : 6.133785362999978e-16\n",
      "RMSE for testing dataset : 0.053149849277220156\n"
     ]
    }
   ],
   "source": [
    "r = Ridge(alpha=0.001)\n",
    "model = r.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"RMSE for training dataset :\",(np.sqrt(np.mean(y_train-y_train_pred)**2)))\n",
    "print(\"RMSE for testing dataset :\",(np.sqrt(np.mean(y_test-y_pred)**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best RMSE for testing dataset in Ridge Regression was given by alpha = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing around with Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for training dataset : 6.561601800385086e-18\n",
      "RMSE for testing dataset : 0.04124973926727658\n"
     ]
    }
   ],
   "source": [
    "l = Lasso(alpha=0.1)\n",
    "model = l.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"RMSE for training dataset :\",(np.sqrt(np.mean(y_train-y_train_pred)**2)))\n",
    "print(\"RMSE for testing dataset :\",(np.sqrt(np.mean(y_test-y_pred)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for training dataset : 4.7164793741168e-16\n",
      "RMSE for testing dataset : 0.06868282811297564\n"
     ]
    }
   ],
   "source": [
    "l = Lasso(alpha=0.01)\n",
    "model = l.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"RMSE for training dataset :\",(np.sqrt(np.mean(y_train-y_train_pred)**2)))\n",
    "print(\"RMSE for testing dataset :\",(np.sqrt(np.mean(y_test-y_pred)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for training dataset : 7.942162819186108e-16\n",
      "RMSE for testing dataset : 0.06589658582543637\n"
     ]
    }
   ],
   "source": [
    "l = Lasso(alpha=0.001)\n",
    "model = l.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"RMSE for training dataset :\",(np.sqrt(np.mean(y_train-y_train_pred)**2)))\n",
    "print(\"RMSE for testing dataset :\",(np.sqrt(np.mean(y_test-y_pred)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for training dataset : 2.131208264765076e-16\n",
      "RMSE for testing dataset : 0.012498738963368871\n"
     ]
    }
   ],
   "source": [
    "l = Lasso(alpha=1)\n",
    "model = l.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"RMSE for training dataset :\",(np.sqrt(np.mean(y_train-y_train_pred)**2)))\n",
    "print(\"RMSE for testing dataset :\",(np.sqrt(np.mean(y_test-y_pred)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for training dataset : 3.286050181632851e-16\n",
      "RMSE for testing dataset : 0.031073969439813984\n"
     ]
    }
   ],
   "source": [
    "l = Lasso(alpha=2)\n",
    "model = l.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"RMSE for training dataset :\",(np.sqrt(np.mean(y_train-y_train_pred)**2)))\n",
    "print(\"RMSE for testing dataset :\",(np.sqrt(np.mean(y_test-y_pred)**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Overfit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_X.sample(n = 1000)\n",
    "Y = Y.sample(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training-validation chunks\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for training dataset : 9.2148511043888e-16\n",
      "RMSE for testing dataset : 0.446211160711661\n"
     ]
    }
   ],
   "source": [
    "lm = LinearRegression()\n",
    "model = lm.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"RMSE for training dataset :\",(np.sqrt(np.mean(y_train-y_train_pred)**2)))\n",
    "print(\"RMSE for testing dataset :\",(np.sqrt(np.mean(y_test-y_pred)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge(alpha):   \n",
    "    r = Ridge(alpha=alpha)\n",
    "    model = r.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"RMSE for Ridge training dataset with alpha :\",alpha,\"=\",(np.sqrt(np.mean(y_train-y_train_pred)**2)))\n",
    "    print(\"RMSE for Ridge testing dataset with alpha :\",alpha,\"=\",(np.sqrt(np.mean(y_test-y_pred)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso(alpha):\n",
    "    l = Lasso(alpha=alpha)\n",
    "    model = l.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"RMSE for Lasso training dataset with alpha :\",alpha,\"=\",(np.sqrt(np.mean(y_train-y_train_pred)**2)))\n",
    "    print(\"RMSE for Lasso testing dataset with alpha :\",alpha,\"=\",(np.sqrt(np.mean(y_test-y_pred)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Ridge training dataset with alpha : 0.01 = 2.1094237467877973e-16\n",
      "RMSE for Ridge testing dataset with alpha : 0.01 = 0.44584737029791927\n",
      "RMSE for Ridge training dataset with alpha : 0.1 = 5.218048215738236e-16\n",
      "RMSE for Ridge testing dataset with alpha : 0.1 = 0.44274295623717924\n",
      "RMSE for Ridge training dataset with alpha : 1 = 5.750955267558311e-16\n",
      "RMSE for Ridge testing dataset with alpha : 1 = 0.42191845794732763\n",
      "RMSE for Ridge training dataset with alpha : 2 = 7.93809462606987e-16\n",
      "RMSE for Ridge testing dataset with alpha : 2 = 0.40862498663795116\n",
      "RMSE for Ridge training dataset with alpha : 5 = 8.726352973553731e-16\n",
      "RMSE for Ridge testing dataset with alpha : 5 = 0.3873574487811883\n"
     ]
    }
   ],
   "source": [
    "ridge(0.01)\n",
    "ridge(0.1)\n",
    "ridge(1)\n",
    "ridge(2)\n",
    "ridge(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Lasso training dataset with alpha : 0.001 = 8.43769498715119e-17\n",
      "RMSE for Lasso testing dataset with alpha : 0.001 = 0.42154538101901695\n",
      "RMSE for Lasso training dataset with alpha : 0.01 = 8.315570454442423e-16\n",
      "RMSE for Lasso testing dataset with alpha : 0.01 = 0.37046864074340713\n",
      "RMSE for Lasso training dataset with alpha : 0.1 = 4.773959005888173e-17\n",
      "RMSE for Lasso testing dataset with alpha : 0.1 = 0.38225491107281434\n",
      "RMSE for Lasso training dataset with alpha : 1 = 7.09432512735475e-16\n",
      "RMSE for Lasso testing dataset with alpha : 1 = 0.3812500000000009\n",
      "RMSE for Lasso training dataset with alpha : 2 = 7.09432512735475e-16\n",
      "RMSE for Lasso testing dataset with alpha : 2 = 0.3812500000000009\n"
     ]
    }
   ],
   "source": [
    "lasso(0.001)\n",
    "lasso(0.01)\n",
    "lasso(0.1)\n",
    "lasso(1)\n",
    "lasso(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The RMSE values for training data for OLS, Ridge and Lasso dataset are almost the same with very less difference. It is also very very low, which means that the data is highly overfit and has a lot of variance. \n",
    "##### The RMSE values for testing data for OLS, Ridge and Lasso  vary, with the lasso regression RMSE being the lowest with an alpha value of 0.01. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The condition number for testing dataset:  inf\n"
     ]
    }
   ],
   "source": [
    "print(\"The condition number for testing dataset: \", np.linalg.cond(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The dataset has a very high variance, and will not perform good if the variable testing dataset is applied on the model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
